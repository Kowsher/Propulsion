{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8947e2c-a06e-4f07-a676-f1ea41f1565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer, GenerationConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training, AdaLoraConfig, AdaLoraConfig\n",
    "\n",
    "from transformers import TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a578a8-de27-49d5-8ab4-04a57735b585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.isfile('/math_10k.json'))  # This should return True if the file is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15178bec-c1a7-4c59-8bc0-73a69bd9e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoModelForCausalLM\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the local JSON file\n",
    "raw_datasets = load_dataset('json', data_files='./math_10k.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff6abb6-d878-438a-8252-b648ceca4db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'answer'],\n",
       "        num_rows: 9919\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef74298-2867-4916-b08b-449abae8133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dave initially had 11 tickets. He spent 5 tickets on a beanie, leaving him with:\\n\\n11 - 5 = 6 tickets\\n\\nHe later won 10 more tickets, so his total number of tickets would be:\\n\\n6 + 10 = 16 tickets\\n\\nTherefore, Dave would have 16 tickets after spending 5 tickets on a beanie and winning 10 more tickets. The answer in Arabic numerals is:\\n\\n16'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffa4932-69e4-4868-b369-00e1545abe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "\n",
    "                ### Instruction:\n",
    "                {data_point[\"instruction\"]}\n",
    "                \n",
    "                ### Input:\n",
    "                {data_point[\"input\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {data_point[\"output\"]}\"\"\" # noqa: E501\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.  \n",
    "\n",
    "                ### Instruction:\n",
    "                {data_point[\"instruction\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {data_point[\"output\"]}\"\"\" # noqa: E501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93634b3-de26-45d1-946b-f770058d514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    # there's probably a way to do this with the tokenizer settings\n",
    "    # but again, gotta move fast\n",
    "    cutoff_len=512\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a70247-7768-49bb-8971-47bb63a56b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_inputs=True\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = generate_prompt({**data_point, \"output\": \"\"})\n",
    "        tokenized_user_prompt = tokenize(user_prompt, add_eos_token=False)\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        tokenized_full_prompt[\"labels\"] = [\n",
    "                                              -100\n",
    "                                          ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "                                                                user_prompt_len:\n",
    "                                                                ]  # could be sped up, probably\n",
    "    return tokenized_full_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e387ff91-2c51-4337-825b-a732cbd40547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Log in using your Hugging Face token\n",
    "login(\"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\")\n",
    "\n",
    "model_name = \"yahma/llama-7b-hf\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "config.hidden_dropout_prob=0.0\n",
    "config.attention_probs_dropout_prob=0.00\n",
    "#config.num_labels=2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6d9fbe-54e3-4a78-938f-a5beea4bfeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7d4af7fd8e403ca95913d472e9da85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = raw_datasets[\"train\"].shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad153a7-f1c8-45bc-b39a-83fc01688c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7547ec9f-ad18-4053-a57e-9713ef91c833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 9919\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faceac05-23fd-47e6-b4d3-311eec20497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Below is an instruction that describes a task. Write a response that appropriately completes the request.  \\n\\n                ### Instruction:\\n                 Mike made 14 dollars mowing lawns and 26 dollars weed eating. If he only spent 5 dollar a week, how long would the money last him? \\n \\n                \\n                ### Response:\\n                1. First, we need to find out how much money Mike made in total:\\n    - 14 (dollars from mowing) + 26 (dollars from weed eating) = 40 dollars\\n2. Next, we need to figure out how many weeks the money will last, given that he spends 5 dollars per week:\\n    - 40 (total dollars made) ÷ 5 (dollars spent per week) = 8 weeks\\n3. Therefore, the money will last Mike 8 weeks.\\n\\nAnswer: 8'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data['input_ids'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c36a1a-afa5-4e03-8f81-c67fad5aaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5a497dd-196a-4fef-8296-9807c7ed057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers.activations import ACT2FN\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8977910b-c948-4208-a6b5-74e3e9620dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53018913ac0b47e7b54da90003f3a2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f275066c-3a5f-42d4-b1bb-5ed2f24559a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leader\n",
    "\n",
    "leader.PEFT(model, method='column', rank=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8435c6b-7f02-404b-8d6d-1962f2e81451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): column()\n",
       "          (k_proj): column()\n",
       "          (v_proj): column()\n",
       "          (o_proj): column()\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): column()\n",
       "          (up_proj): column()\n",
       "          (down_proj): column()\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): column()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2ae80e-7a76-49dc-8a39-e16c9a67280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters:4441856, percentage:  0.03277787328256677\n"
     ]
    }
   ],
   "source": [
    "# Count of trainable parameters\n",
    "total_trainable_params = 0\n",
    "total =  0\n",
    "# Print trainable parameters and count their total number\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        #print(f\"Parameter name: {name}, Shape: {param.shape}\")\n",
    "        \n",
    "        total_trainable_params += param.numel()\n",
    "    total+=param.numel()\n",
    "\n",
    "print(f\"Total trainable parameters:{total_trainable_params}, percentage:  {total_trainable_params/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e712870-8165-40df-a94b-63e9ed11b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total trainable parameters:3145728, percentage:  0.00046661712910165873 lora\n",
    "#Total trainable parameters:1409024, percentage:  0.010635666584219638 leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0f8d1d-2b84-477d-b5a0-4f757d49f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f291c573-2dd7-4196-b130-d6e9289fc7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f5fd3f8-fd96-4fde-8d34-1ca8268e3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='659' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 659/1240 1:53:20 < 1:40:14, 0.10 it/s, Epoch 1.06/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.658800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.607300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.568300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 35\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqnli_dir\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2021\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2357\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2357\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2360\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2361\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2362\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2363\u001b[0m ):\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3454\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3454\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3459\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3460\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3501\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3500\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3501\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3502\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1185\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1182\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:996\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    984\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    985\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    986\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    993\u001b[0m         position_embeddings,\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:728\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:613\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[1;32m    612\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[0;32m--> 613\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    616\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/leader.py:63\u001b[0m, in \u001b[0;36mcolumn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 63\u001b[0m     out_trainable \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     out_non_trainable \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnon_trainable_weight, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_trainable \u001b[38;5;241m+\u001b[39m out_non_trainable\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='qnli_dir',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.00,\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    gradient_accumulation_steps= 2,\n",
    "\n",
    "    logging_steps=100,\n",
    "   \n",
    "    #load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    #eval_dataset=tokenized_datasets[\"validation\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d62ff1f5-60ed-4e61-b5b6-71158a37b155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8be80a801f43e193a0700b13bfa6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/460k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d38249f4174e5384e151262e185c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_datasets = load_dataset('json', data_files='https://raw.githubusercontent.com/AGI-Edgerunners/LLM-Adapters/refs/heads/main/dataset/SVAMP/test.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "66e8579a-32bc-4416-b680-cad2fd0d2c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "912fb79a-8eb0-4856-84bc-899000925332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6aeb0b0cd14f6897a66cf9c80380d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = test_datasets[\"train\"].shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "292272a9-c7f2-4b0c-9a3c-86e540af7fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1a95aff6-ea67-4180-a673-a3caf3b945cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Below is an instruction that describes a task. Write a response that appropriately completes the request.  \\n\\n                ### Instruction:\\n                7 red peaches, 15 yellow peaches and 8 green peaches are in the basket. How many peaches are in the basket?\\n                \\n                ### Response:\\n                \\nA: There are 7 red peaches, 15 yellow peaches and 8 green peaches. In total there are 7 + 15 + 8 = 30 peaches. The answer'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_data['input_ids'][154][:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1408ca1b-4fdf-4880-9b94-be9031a93467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d883fa778d455483c77c9858333219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "k = 0\n",
    "ck = 0\n",
    "result = []\n",
    "truth = []\n",
    "for i in tqdm(range(len(test_data['input_ids']))):\n",
    "    input_truth = torch.tensor(test_data['input_ids'][i])\n",
    "    input_ids = torch.tensor(test_data['input_ids'][i][:-5]).unsqueeze(0).to(model.device)\n",
    "    attention_mask = torch.tensor(test_data['attention_mask'][i][:-5]).unsqueeze(0).to(model.device)\n",
    "    #print(input_ids.shape, attention_mask.shape)\n",
    "    output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=input_ids.shape[1]+7)\n",
    "\n",
    "    try:\n",
    "        output = tokenizer.decode(output[0]).split('The answer is')[1]\n",
    "        true = tokenizer.decode(input_truth).split('The answer is')[1]\n",
    "        #print(output, float(re.findall(r'\\d+\\.\\d+|\\d+', output)[0])\n",
    "        result.append(float(re.findall(r'\\d+\\.\\d+|\\d+', output)[0]))\n",
    "        truth.append(float(re.findall(r'\\d+\\.\\d+|\\d+', true)[0]))\n",
    "    except:\n",
    "        ck = 1\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9303a3f0-1c24-41a2-9edc-98914f5dffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[217.0,\n",
       " 29.0,\n",
       " 82.0,\n",
       " 293.0,\n",
       " 23.0,\n",
       " 14.0,\n",
       " 47.0,\n",
       " 6.0,\n",
       " 153.0,\n",
       " 7.7,\n",
       " 30.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 22.0,\n",
       " 37.0,\n",
       " 14.0,\n",
       " 7.0,\n",
       " 62.0,\n",
       " 92.0,\n",
       " 38608.0,\n",
       " 720.0,\n",
       " 272.0,\n",
       " 20.0,\n",
       " 2.0,\n",
       " 24.0,\n",
       " 7.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 30057.0,\n",
       " 208.0,\n",
       " 29.0,\n",
       " 2.0,\n",
       " 21.0,\n",
       " 68.0,\n",
       " 10.0,\n",
       " 81.0,\n",
       " 89.0,\n",
       " 25.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 3.0,\n",
       " 22.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 12.0,\n",
       " 2.0,\n",
       " 1396.0,\n",
       " 26180.0,\n",
       " 204.0,\n",
       " 13.0,\n",
       " 111.0,\n",
       " 143.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 68.0,\n",
       " 17.0,\n",
       " 220.0,\n",
       " 8.0,\n",
       " 17.0,\n",
       " 450.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 7.0,\n",
       " 6.0,\n",
       " 18.0,\n",
       " 3.0,\n",
       " 13.0,\n",
       " 2.0,\n",
       " 53.0,\n",
       " 265.0,\n",
       " 21.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 308.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 9.0,\n",
       " 192.0,\n",
       " 41.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 31.0,\n",
       " 192.0,\n",
       " 17.0,\n",
       " 14.0,\n",
       " 6.0,\n",
       " 488.0,\n",
       " 21.0,\n",
       " 6.0,\n",
       " 19.0,\n",
       " 42.0,\n",
       " 70.0,\n",
       " 52.0,\n",
       " 3.0,\n",
       " 20.0,\n",
       " 48.0,\n",
       " 1.0,\n",
       " 21.0,\n",
       " 1.0,\n",
       " 33.0,\n",
       " 123.0,\n",
       " 28.0,\n",
       " 21.7,\n",
       " 186.0,\n",
       " 3.0,\n",
       " 57.0,\n",
       " 17137.0,\n",
       " 1124.0,\n",
       " 23.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1307.0,\n",
       " 22.0,\n",
       " 7.0,\n",
       " 12.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 11.0,\n",
       " 21.0,\n",
       " 5.0,\n",
       " 7.0,\n",
       " 276.0,\n",
       " 2.0,\n",
       " 19.0,\n",
       " 687.0,\n",
       " 51.0,\n",
       " 469.0,\n",
       " 4.0,\n",
       " 12.0,\n",
       " 57.0,\n",
       " 232.0,\n",
       " 66.0,\n",
       " 111.0,\n",
       " 30.0,\n",
       " 41.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 111.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 348.0,\n",
       " 137.0,\n",
       " 102.0,\n",
       " 15.0,\n",
       " 1.0,\n",
       " 333.0,\n",
       " 26.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 33.0,\n",
       " 420.0,\n",
       " 638.0,\n",
       " 3.0,\n",
       " 265.0,\n",
       " 24.0,\n",
       " 183.0,\n",
       " 1.0,\n",
       " 2.5,\n",
       " 14.0,\n",
       " 2.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 21.0,\n",
       " 76.0,\n",
       " 4.0,\n",
       " 125.0,\n",
       " 4.0,\n",
       " 27.0,\n",
       " 31.0,\n",
       " 1.0,\n",
       " 7.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 83.0,\n",
       " 33.0,\n",
       " 17.0,\n",
       " 78.0,\n",
       " 56.0,\n",
       " 31.0,\n",
       " 308.0,\n",
       " 2.0,\n",
       " 18.0,\n",
       " 4.0,\n",
       " 249.0,\n",
       " 38.0,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 26.0,\n",
       " 13.0,\n",
       " 410.0,\n",
       " 17.67,\n",
       " 102.0,\n",
       " 39.0,\n",
       " 45.0,\n",
       " 103.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 50.0,\n",
       " 2.0,\n",
       " 25.0,\n",
       " 7.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 484.0,\n",
       " 68.0,\n",
       " 4.0,\n",
       " 41.0,\n",
       " 13.27,\n",
       " 11346.0,\n",
       " 89.0,\n",
       " 12558.0,\n",
       " 0.83,\n",
       " 2.0,\n",
       " 36.0,\n",
       " 1.0,\n",
       " 458988.0,\n",
       " 127.0,\n",
       " 1.22,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 113511.0,\n",
       " 10.0,\n",
       " 54.0,\n",
       " 32.0,\n",
       " 24.0,\n",
       " 26.0,\n",
       " 37.0,\n",
       " 5.0,\n",
       " 13.0,\n",
       " 10.0,\n",
       " 21.0,\n",
       " 4.0,\n",
       " 31.0,\n",
       " 26.0,\n",
       " 102.0,\n",
       " 211.0,\n",
       " 14.0,\n",
       " 3.0,\n",
       " 88.0,\n",
       " 43.0,\n",
       " 30.0,\n",
       " 10485056.0,\n",
       " 17.0,\n",
       " 105.0,\n",
       " 14.0,\n",
       " 34.0,\n",
       " 25.0,\n",
       " 71.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 53.0,\n",
       " 20.0,\n",
       " 365.0,\n",
       " 2.0,\n",
       " 30.0,\n",
       " 5.0,\n",
       " 223.0,\n",
       " 10.0,\n",
       " 65.0,\n",
       " 15.0,\n",
       " 242.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 10.0,\n",
       " 45.0,\n",
       " 19.0,\n",
       " 105.0,\n",
       " 168.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 347.0,\n",
       " 78252.0,\n",
       " 14.0,\n",
       " 94.0,\n",
       " 482.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 4300.0,\n",
       " 18.0,\n",
       " 3.0,\n",
       " 45.0,\n",
       " 4.0,\n",
       " 56.0,\n",
       " 337.0,\n",
       " 15.0,\n",
       " 10011.0,\n",
       " 220.2,\n",
       " 4.0,\n",
       " 16.0,\n",
       " 15.0,\n",
       " 32.0,\n",
       " 18.0,\n",
       " 112.0,\n",
       " 3.0,\n",
       " 194.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 183.0,\n",
       " 2.0,\n",
       " 124.0,\n",
       " 1463.0,\n",
       " 16.0,\n",
       " 9.0,\n",
       " 139.0,\n",
       " 106.0,\n",
       " 22.0,\n",
       " 58.0,\n",
       " 13.0,\n",
       " 84.0,\n",
       " 110.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 9.0,\n",
       " 24578.0,\n",
       " 15.0,\n",
       " 150780.0,\n",
       " 6.0,\n",
       " 71.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 369.0,\n",
       " 394.0,\n",
       " 89.0,\n",
       " 3.0,\n",
       " 17.0,\n",
       " 27.0,\n",
       " 5.0,\n",
       " 551.0,\n",
       " 13.0,\n",
       " 90.0,\n",
       " 38.0,\n",
       " 15.0,\n",
       " 17.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 230.0,\n",
       " 14.0,\n",
       " 17.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 50.0,\n",
       " 10.0,\n",
       " 7.0,\n",
       " 63.0,\n",
       " 1.0,\n",
       " 18.0,\n",
       " 16.0,\n",
       " 18.0,\n",
       " 737.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 3.0,\n",
       " 16.0,\n",
       " 39.0,\n",
       " 28.0,\n",
       " 41.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 662.0,\n",
       " 654.0,\n",
       " 8.0,\n",
       " 842.0,\n",
       " 7.0,\n",
       " 16.0,\n",
       " 45.0,\n",
       " 826.0,\n",
       " 2.0,\n",
       " 27180.0,\n",
       " 3.0,\n",
       " 24.0,\n",
       " 93.0,\n",
       " 22.0,\n",
       " 95.0,\n",
       " 2.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 7.0,\n",
       " 274.0,\n",
       " 44.0,\n",
       " 32.0,\n",
       " 1.0,\n",
       " 253.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 12.0,\n",
       " 566.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 367.0,\n",
       " 23.0,\n",
       " 90.0,\n",
       " 10.0,\n",
       " 39.0,\n",
       " 7.0,\n",
       " 65.0,\n",
       " 4.0,\n",
       " 25.0,\n",
       " 1891.0,\n",
       " 10.0,\n",
       " 96.0,\n",
       " 756.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 614.0,\n",
       " 81.0,\n",
       " 66.0,\n",
       " 574.0,\n",
       " 10.0,\n",
       " 58.0,\n",
       " 3.0,\n",
       " 65.0,\n",
       " 67.0,\n",
       " 345.0,\n",
       " 640.0,\n",
       " 510.0,\n",
       " 14.0,\n",
       " 6.0,\n",
       " 61.0,\n",
       " 1414.0,\n",
       " 1.0,\n",
       " 1538832.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 2.0,\n",
       " 8702.0,\n",
       " 3021.0,\n",
       " 14.0,\n",
       " 5.0,\n",
       " 119.0,\n",
       " 2.0,\n",
       " 94.0,\n",
       " 3.0,\n",
       " 38.0,\n",
       " 1081.0,\n",
       " 8.0,\n",
       " 8142.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 294.0,\n",
       " 858.0,\n",
       " 18.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 34.0,\n",
       " 7.0,\n",
       " 10.0,\n",
       " 66.0,\n",
       " 7.0,\n",
       " 44.0,\n",
       " 1.0,\n",
       " 569.0,\n",
       " 3.0,\n",
       " 58.0,\n",
       " 946.0,\n",
       " 66.0,\n",
       " 101.0,\n",
       " 28.0,\n",
       " 131.0,\n",
       " 68.0,\n",
       " 20.0,\n",
       " 11.0,\n",
       " 175.0,\n",
       " 41.0,\n",
       " 90.0,\n",
       " 146.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 190.0,\n",
       " 621.0,\n",
       " 27.0,\n",
       " 1.0,\n",
       " 154.0,\n",
       " 252.0,\n",
       " 4.0,\n",
       " 143550.0,\n",
       " 98.0,\n",
       " 314.0,\n",
       " 21.0,\n",
       " 96.0,\n",
       " 5700.0,\n",
       " 3.0,\n",
       " 42.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 76.0,\n",
       " 481.0,\n",
       " 11.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 26.0,\n",
       " 1541.0,\n",
       " 78.0,\n",
       " 22.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 15.0,\n",
       " 4.0,\n",
       " 926.0,\n",
       " 10.0,\n",
       " 91.0,\n",
       " 35.0,\n",
       " 1.0,\n",
       " 45.0,\n",
       " 10.0,\n",
       " 828462.0,\n",
       " 8.0,\n",
       " 210.0,\n",
       " 7.0,\n",
       " 81.0,\n",
       " 1.0,\n",
       " 29.0,\n",
       " 14.0,\n",
       " 84.0,\n",
       " 34.0,\n",
       " 8.0,\n",
       " 1032.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 2.6,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 32.0,\n",
       " 64.0,\n",
       " 3.0,\n",
       " 60.0,\n",
       " 1.0,\n",
       " 63.0,\n",
       " 30.0,\n",
       " 14.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 149.0,\n",
       " 23.0,\n",
       " 4.0,\n",
       " 92.0,\n",
       " 20.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 1080.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 22.0,\n",
       " 42.0,\n",
       " 180.0,\n",
       " 40.0,\n",
       " 69.0,\n",
       " 37.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 44.0,\n",
       " 145.0,\n",
       " 20.0,\n",
       " 25.0,\n",
       " 40.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 76.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 32.0,\n",
       " 11.0,\n",
       " 127.0,\n",
       " 32.0,\n",
       " 325.0,\n",
       " 92.0,\n",
       " 1.0,\n",
       " 82.0,\n",
       " 11.0,\n",
       " 39.0,\n",
       " 109.0,\n",
       " 1007.0,\n",
       " 37.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 720.0,\n",
       " 3.0,\n",
       " 10.0,\n",
       " 4.0,\n",
       " 62.0,\n",
       " 49.0,\n",
       " 3.0,\n",
       " 37.0,\n",
       " 60.0,\n",
       " 1.0,\n",
       " 22.0,\n",
       " 102.0,\n",
       " 152.0,\n",
       " 117.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 25.0,\n",
       " 2.0,\n",
       " 61.0,\n",
       " 949.0,\n",
       " 13.0,\n",
       " 28.0,\n",
       " 72.0,\n",
       " 2523.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 18.0,\n",
       " 10.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 390.0,\n",
       " 1149.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 11.0,\n",
       " 2050.0,\n",
       " 198.0,\n",
       " 15.0,\n",
       " 469.0,\n",
       " 1848.0,\n",
       " 42.0,\n",
       " 67.0,\n",
       " 4.0,\n",
       " 784.0,\n",
       " 9.0,\n",
       " 136.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 41.0,\n",
       " 10.0,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 25.0,\n",
       " 120.0,\n",
       " 12.0,\n",
       " 366.0,\n",
       " 2080.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 69.0,\n",
       " 105.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 174080.0,\n",
       " 56.0,\n",
       " 1.0,\n",
       " 12.0,\n",
       " 22.0,\n",
       " 118.0,\n",
       " 2.0,\n",
       " 6384.0,\n",
       " 1.0,\n",
       " 56.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 70.0,\n",
       " 23.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 45.0,\n",
       " 280.0,\n",
       " 28.0,\n",
       " 1.0,\n",
       " 8106.0,\n",
       " 26.0,\n",
       " 1.0,\n",
       " 99.0,\n",
       " 28.0,\n",
       " 80.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1088.0,\n",
       " 7.0,\n",
       " 113.0,\n",
       " 8.0,\n",
       " 16.0,\n",
       " 4.0,\n",
       " 121.0,\n",
       " 29.0,\n",
       " 47.0,\n",
       " 23.0,\n",
       " 350.0,\n",
       " 9.0,\n",
       " 2.0,\n",
       " 14.0,\n",
       " 19.0,\n",
       " 14.0,\n",
       " 19.0,\n",
       " 30.0,\n",
       " 42.0,\n",
       " 14.0,\n",
       " 405.0,\n",
       " 3.0,\n",
       " 27.0,\n",
       " 2.0,\n",
       " 39.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 10.0,\n",
       " 19.0,\n",
       " 18.0,\n",
       " 54.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 32.0,\n",
       " 5.0,\n",
       " 2.0,\n",
       " 72.0,\n",
       " 10.0,\n",
       " 63.0,\n",
       " 2.0,\n",
       " 20.0,\n",
       " 248.4,\n",
       " 26.0,\n",
       " 7.0,\n",
       " 5.0,\n",
       " 21.0,\n",
       " 38.0,\n",
       " 6840.0,\n",
       " 2.0,\n",
       " 60.0,\n",
       " 1124.0,\n",
       " 98.0,\n",
       " 28.0,\n",
       " 12.0,\n",
       " 22.0,\n",
       " 1.0,\n",
       " 22.0,\n",
       " 10.0,\n",
       " 140.0,\n",
       " 32.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 11.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 587.0,\n",
       " 33.0,\n",
       " 4.0,\n",
       " 25.0,\n",
       " 37.0,\n",
       " 7.0,\n",
       " 63.0,\n",
       " 298.0,\n",
       " 12.0,\n",
       " 69.0,\n",
       " 54.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 12.0,\n",
       " 420.0,\n",
       " 600.0,\n",
       " 13.0,\n",
       " 5.0,\n",
       " 520.0,\n",
       " 13.0,\n",
       " 11.0,\n",
       " 33.0,\n",
       " 20.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 128.0,\n",
       " 3.0,\n",
       " 807.0,\n",
       " 22.0,\n",
       " 6.0,\n",
       " 25.0,\n",
       " 28.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 12.0,\n",
       " 6.0,\n",
       " 156.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 11.0,\n",
       " 24.0,\n",
       " 72.0,\n",
       " 2673.0,\n",
       " 19.0,\n",
       " 54.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 12.0,\n",
       " 33.0,\n",
       " 17.0,\n",
       " 13.0,\n",
       " 8.0,\n",
       " 11.0,\n",
       " 1.0,\n",
       " 10.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 13.0,\n",
       " 19.0,\n",
       " 15.0,\n",
       " 27.0,\n",
       " 268627.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 11.0,\n",
       " 24.0,\n",
       " 125.0,\n",
       " 1145.0,\n",
       " 126.0,\n",
       " 20.0,\n",
       " 574.0,\n",
       " 22.0,\n",
       " 75.0,\n",
       " 112.0,\n",
       " 255.0,\n",
       " 156.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 24.0,\n",
       " 2.0,\n",
       " 229.0,\n",
       " 2184.0,\n",
       " 45.0,\n",
       " 13.0,\n",
       " 16.0,\n",
       " 21.0,\n",
       " 96.0,\n",
       " 53.0,\n",
       " 0.84,\n",
       " 120178.0,\n",
       " 22.0,\n",
       " 34.0,\n",
       " 2.0,\n",
       " 42.0,\n",
       " 91.0,\n",
       " 20.0,\n",
       " 10.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 1.44,\n",
       " 17.0,\n",
       " 101.0,\n",
       " 17.0,\n",
       " 59.0,\n",
       " 22.0,\n",
       " 3168.0,\n",
       " 30.0,\n",
       " 229.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 83.0,\n",
       " 31.0,\n",
       " 606.0,\n",
       " 574664.0,\n",
       " 6.0,\n",
       " 3834.0,\n",
       " 2436.0,\n",
       " 6.0,\n",
       " 174.0,\n",
       " 3.0,\n",
       " 60.0,\n",
       " 20.0,\n",
       " 14.0,\n",
       " 455.0,\n",
       " 106.0,\n",
       " 12.0,\n",
       " 70.0,\n",
       " 170.0,\n",
       " 35.0,\n",
       " 72.0,\n",
       " 15.0,\n",
       " 171.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 130.0,\n",
       " 592.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 17.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 43.0,\n",
       " 5852.0,\n",
       " 10.0,\n",
       " 45.0,\n",
       " 14.0,\n",
       " 9.0,\n",
       " 99.0,\n",
       " 27.0,\n",
       " 1.0,\n",
       " 11.0,\n",
       " 1.0,\n",
       " 2.0]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0555339e-8a24-4f5d-8854-9b2451b87878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[217.0,\n",
       " 29.0,\n",
       " 82.0,\n",
       " 293.0,\n",
       " 23.0,\n",
       " 14.0,\n",
       " 47.0,\n",
       " 6.0,\n",
       " 153.0,\n",
       " 7.7,\n",
       " 30.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 22.0,\n",
       " 37.0,\n",
       " 14.0,\n",
       " 7.0,\n",
       " 62.0,\n",
       " 92.0,\n",
       " 38608.0,\n",
       " 720.0,\n",
       " 272.0,\n",
       " 20.0,\n",
       " 2.0,\n",
       " 24.0,\n",
       " 7.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 30057.0,\n",
       " 208.0,\n",
       " 29.0,\n",
       " 2.0,\n",
       " 21.0,\n",
       " 68.0,\n",
       " 10.0,\n",
       " 81.0,\n",
       " 89.0,\n",
       " 25.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 3.0,\n",
       " 22.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 12.0,\n",
       " 2.0,\n",
       " 1396.0,\n",
       " 26180.0,\n",
       " 204.0,\n",
       " 13.0,\n",
       " 111.0,\n",
       " 143.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 13.0,\n",
       " 17.0,\n",
       " 220.0,\n",
       " 8.0,\n",
       " 17.0,\n",
       " 450.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 7.0,\n",
       " 6.0,\n",
       " 18.0,\n",
       " 3.0,\n",
       " 13.0,\n",
       " 2.0,\n",
       " 53.0,\n",
       " 265.0,\n",
       " 21.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 308.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 9.0,\n",
       " 192.0,\n",
       " 41.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 31.0,\n",
       " 192.0,\n",
       " 17.0,\n",
       " 14.0,\n",
       " 6.0,\n",
       " 488.0,\n",
       " 21.0,\n",
       " 6.0,\n",
       " 19.0,\n",
       " 42.0,\n",
       " 70.0,\n",
       " 52.0,\n",
       " 3.0,\n",
       " 20.0,\n",
       " 48.0,\n",
       " 1.0,\n",
       " 21.0,\n",
       " 1.0,\n",
       " 33.0,\n",
       " 123.0,\n",
       " 28.0,\n",
       " 21.7,\n",
       " 186.0,\n",
       " 3.0,\n",
       " 57.0,\n",
       " 17137.0,\n",
       " 1124.0,\n",
       " 23.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1307.0,\n",
       " 22.0,\n",
       " 7.0,\n",
       " 12.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 11.0,\n",
       " 21.0,\n",
       " 5.0,\n",
       " 7.0,\n",
       " 276.0,\n",
       " 2.0,\n",
       " 19.0,\n",
       " 687.0,\n",
       " 51.0,\n",
       " 469.0,\n",
       " 4.0,\n",
       " 12.0,\n",
       " 57.0,\n",
       " 232.0,\n",
       " 66.0,\n",
       " 111.0,\n",
       " 30.0,\n",
       " 41.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 111.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 348.0,\n",
       " 137.0,\n",
       " 102.0,\n",
       " 15.0,\n",
       " 1.0,\n",
       " 333.0,\n",
       " 26.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 33.0,\n",
       " 420.0,\n",
       " 638.0,\n",
       " 3.0,\n",
       " 265.0,\n",
       " 24.0,\n",
       " 183.0,\n",
       " 1.0,\n",
       " 2.5,\n",
       " 14.0,\n",
       " 2.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 21.0,\n",
       " 76.0,\n",
       " 4.0,\n",
       " 125.0,\n",
       " 4.0,\n",
       " 27.0,\n",
       " 31.0,\n",
       " 1.0,\n",
       " 7.0,\n",
       " 70.0,\n",
       " 63.0,\n",
       " 83.0,\n",
       " 33.0,\n",
       " 17.0,\n",
       " 78.0,\n",
       " 56.0,\n",
       " 31.0,\n",
       " 308.0,\n",
       " 2.0,\n",
       " 18.0,\n",
       " 4.0,\n",
       " 249.0,\n",
       " 38.0,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 26.0,\n",
       " 13.0,\n",
       " 410.0,\n",
       " 17.0,\n",
       " 102.0,\n",
       " 39.0,\n",
       " 45.0,\n",
       " 103.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 50.0,\n",
       " 2.0,\n",
       " 25.0,\n",
       " 7.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 484.0,\n",
       " 68.0,\n",
       " 4.0,\n",
       " 41.0,\n",
       " 13.27,\n",
       " 11346.0,\n",
       " 89.0,\n",
       " 12558.0,\n",
       " 0.83,\n",
       " 2.0,\n",
       " 36.0,\n",
       " 1.0,\n",
       " 458988.0,\n",
       " 127.0,\n",
       " 1.22,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 113511.0,\n",
       " 10.0,\n",
       " 54.0,\n",
       " 32.0,\n",
       " 24.0,\n",
       " 26.0,\n",
       " 37.0,\n",
       " 5.0,\n",
       " 13.0,\n",
       " 10.0,\n",
       " 21.0,\n",
       " 4.0,\n",
       " 31.0,\n",
       " 26.0,\n",
       " 102.0,\n",
       " 211.0,\n",
       " 14.0,\n",
       " 3.0,\n",
       " 88.0,\n",
       " 43.0,\n",
       " 30.0,\n",
       " 10485056.0,\n",
       " 17.0,\n",
       " 105.0,\n",
       " 14.0,\n",
       " 34.0,\n",
       " 25.0,\n",
       " 67.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 53.0,\n",
       " 20.0,\n",
       " 365.0,\n",
       " 2.0,\n",
       " 30.0,\n",
       " 5.0,\n",
       " 223.0,\n",
       " 10.0,\n",
       " 65.0,\n",
       " 15.0,\n",
       " 242.0,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 10.0,\n",
       " 45.0,\n",
       " 19.0,\n",
       " 105.0,\n",
       " 210.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 347.0,\n",
       " 78252.0,\n",
       " 14.0,\n",
       " 94.0,\n",
       " 482.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 4300.0,\n",
       " 18.0,\n",
       " 3.0,\n",
       " 45.0,\n",
       " 4.0,\n",
       " 56.0,\n",
       " 337.0,\n",
       " 15.0,\n",
       " 10011.0,\n",
       " 220.0,\n",
       " 4.0,\n",
       " 16.0,\n",
       " 15.0,\n",
       " 32.0,\n",
       " 18.0,\n",
       " 112.0,\n",
       " 3.0,\n",
       " 194.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 183.0,\n",
       " 2.0,\n",
       " 124.0,\n",
       " 1463.0,\n",
       " 16.0,\n",
       " 13.0,\n",
       " 139.0,\n",
       " 106.0,\n",
       " 22.0,\n",
       " 58.0,\n",
       " 13.0,\n",
       " 84.0,\n",
       " 110.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 9.0,\n",
       " 24578.0,\n",
       " 15.0,\n",
       " 150780.0,\n",
       " 6.0,\n",
       " 71.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 369.0,\n",
       " 394.0,\n",
       " 89.0,\n",
       " 3.0,\n",
       " 17.0,\n",
       " 27.0,\n",
       " 5.0,\n",
       " 551.0,\n",
       " 13.0,\n",
       " 90.0,\n",
       " 38.0,\n",
       " 15.0,\n",
       " 17.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 230.0,\n",
       " 14.0,\n",
       " 17.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 50.0,\n",
       " 10.0,\n",
       " 7.0,\n",
       " 63.0,\n",
       " 1.0,\n",
       " 18.0,\n",
       " 16.0,\n",
       " 18.0,\n",
       " 737.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 3.0,\n",
       " 16.0,\n",
       " 39.0,\n",
       " 28.0,\n",
       " 41.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 662.0,\n",
       " 654.0,\n",
       " 8.0,\n",
       " 842.0,\n",
       " 7.0,\n",
       " 16.0,\n",
       " 45.0,\n",
       " 826.0,\n",
       " 2.0,\n",
       " 27180.0,\n",
       " 3.0,\n",
       " 24.0,\n",
       " 93.0,\n",
       " 22.0,\n",
       " 95.0,\n",
       " 2.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 7.0,\n",
       " 274.0,\n",
       " 44.0,\n",
       " 32.0,\n",
       " 1.0,\n",
       " 253.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 12.0,\n",
       " 566.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 367.0,\n",
       " 23.0,\n",
       " 90.0,\n",
       " 10.0,\n",
       " 39.0,\n",
       " 7.0,\n",
       " 65.0,\n",
       " 4.0,\n",
       " 25.0,\n",
       " 1891.0,\n",
       " 10.0,\n",
       " 96.0,\n",
       " 756.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 614.0,\n",
       " 81.0,\n",
       " 66.0,\n",
       " 574.0,\n",
       " 10.0,\n",
       " 58.0,\n",
       " 3.0,\n",
       " 65.0,\n",
       " 67.0,\n",
       " 345.0,\n",
       " 640.0,\n",
       " 510.0,\n",
       " 14.0,\n",
       " 6.0,\n",
       " 61.0,\n",
       " 1414.0,\n",
       " 1.0,\n",
       " 1538832.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 2.0,\n",
       " 8702.0,\n",
       " 3021.0,\n",
       " 14.0,\n",
       " 5.0,\n",
       " 119.0,\n",
       " 2.0,\n",
       " 94.0,\n",
       " 3.0,\n",
       " 38.0,\n",
       " 1081.0,\n",
       " 8.0,\n",
       " 8142.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 294.0,\n",
       " 858.0,\n",
       " 18.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 14.0,\n",
       " 34.0,\n",
       " 7.0,\n",
       " 10.0,\n",
       " 66.0,\n",
       " 7.0,\n",
       " 44.0,\n",
       " 1.0,\n",
       " 569.0,\n",
       " 3.0,\n",
       " 58.0,\n",
       " 946.0,\n",
       " 66.0,\n",
       " 101.0,\n",
       " 28.0,\n",
       " 131.0,\n",
       " 68.0,\n",
       " 20.0,\n",
       " 11.0,\n",
       " 175.0,\n",
       " 41.0,\n",
       " 90.0,\n",
       " 146.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 190.0,\n",
       " 621.0,\n",
       " 27.0,\n",
       " 1.0,\n",
       " 154.0,\n",
       " 252.0,\n",
       " 4.0,\n",
       " 143550.0,\n",
       " 98.0,\n",
       " 314.0,\n",
       " 21.0,\n",
       " 96.0,\n",
       " 5700.0,\n",
       " 3.0,\n",
       " 42.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 76.0,\n",
       " 481.0,\n",
       " 11.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 26.0,\n",
       " 1541.0,\n",
       " 78.0,\n",
       " 22.0,\n",
       " 4.0,\n",
       " 19.0,\n",
       " 15.0,\n",
       " 4.0,\n",
       " 926.0,\n",
       " 10.0,\n",
       " 91.0,\n",
       " 35.0,\n",
       " 1.0,\n",
       " 45.0,\n",
       " 10.0,\n",
       " 828462.0,\n",
       " 8.0,\n",
       " 210.0,\n",
       " 7.0,\n",
       " 81.0,\n",
       " 1.0,\n",
       " 29.0,\n",
       " 14.0,\n",
       " 84.0,\n",
       " 34.0,\n",
       " 8.0,\n",
       " 1032.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 32.0,\n",
       " 64.0,\n",
       " 3.0,\n",
       " 60.0,\n",
       " 1.0,\n",
       " 63.0,\n",
       " 30.0,\n",
       " 14.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 149.0,\n",
       " 23.0,\n",
       " 4.0,\n",
       " 92.0,\n",
       " 20.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 1080.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 22.0,\n",
       " 42.0,\n",
       " 180.0,\n",
       " 40.0,\n",
       " 69.0,\n",
       " 37.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 44.0,\n",
       " 145.0,\n",
       " 20.0,\n",
       " 25.0,\n",
       " 40.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 76.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 32.0,\n",
       " 11.0,\n",
       " 127.0,\n",
       " 32.0,\n",
       " 325.0,\n",
       " 92.0,\n",
       " 1.0,\n",
       " 82.0,\n",
       " 11.0,\n",
       " 39.0,\n",
       " 109.0,\n",
       " 1007.0,\n",
       " 37.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 720.0,\n",
       " 3.0,\n",
       " 10.0,\n",
       " 4.0,\n",
       " 62.0,\n",
       " 49.0,\n",
       " 3.0,\n",
       " 37.0,\n",
       " 60.0,\n",
       " 1.0,\n",
       " 22.0,\n",
       " 102.0,\n",
       " 32.0,\n",
       " 117.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 25.0,\n",
       " 2.0,\n",
       " 61.0,\n",
       " 949.0,\n",
       " 13.0,\n",
       " 28.0,\n",
       " 72.0,\n",
       " 2523.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 18.0,\n",
       " 10.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 390.0,\n",
       " 1149.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 11.0,\n",
       " 2050.0,\n",
       " 198.0,\n",
       " 15.0,\n",
       " 469.0,\n",
       " 1848.0,\n",
       " 42.0,\n",
       " 67.0,\n",
       " 4.0,\n",
       " 784.0,\n",
       " 9.0,\n",
       " 136.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 41.0,\n",
       " 10.0,\n",
       " 6.0,\n",
       " 11.0,\n",
       " 25.0,\n",
       " 120.0,\n",
       " 12.0,\n",
       " 366.0,\n",
       " 2080.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 69.0,\n",
       " 105.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 174080.0,\n",
       " 56.0,\n",
       " 1.0,\n",
       " 12.0,\n",
       " 22.0,\n",
       " 118.0,\n",
       " 2.0,\n",
       " 6384.0,\n",
       " 1.0,\n",
       " 56.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 70.0,\n",
       " 23.0,\n",
       " 4.0,\n",
       " 14.0,\n",
       " 45.0,\n",
       " 280.0,\n",
       " 28.0,\n",
       " 1.0,\n",
       " 8106.0,\n",
       " 26.0,\n",
       " 1.0,\n",
       " 99.0,\n",
       " 28.0,\n",
       " 80.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1088.0,\n",
       " 7.0,\n",
       " 113.0,\n",
       " 8.0,\n",
       " 16.0,\n",
       " 4.0,\n",
       " 121.0,\n",
       " 29.0,\n",
       " 47.0,\n",
       " 23.0,\n",
       " 350.0,\n",
       " 9.0,\n",
       " 2.0,\n",
       " 14.0,\n",
       " 19.0,\n",
       " 14.0,\n",
       " 19.0,\n",
       " 30.0,\n",
       " 42.0,\n",
       " 14.0,\n",
       " 405.0,\n",
       " 3.0,\n",
       " 27.0,\n",
       " 2.0,\n",
       " 39.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 10.0,\n",
       " 2.0,\n",
       " 18.0,\n",
       " 54.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 32.0,\n",
       " 5.0,\n",
       " 2.0,\n",
       " 72.0,\n",
       " 10.0,\n",
       " 63.0,\n",
       " 2.0,\n",
       " 20.0,\n",
       " 248.4,\n",
       " 26.0,\n",
       " 7.0,\n",
       " 5.0,\n",
       " 21.0,\n",
       " 38.0,\n",
       " 6840.0,\n",
       " 2.0,\n",
       " 60.0,\n",
       " 1124.0,\n",
       " 98.0,\n",
       " 28.0,\n",
       " 12.0,\n",
       " 22.0,\n",
       " 1.0,\n",
       " 22.0,\n",
       " 10.0,\n",
       " 140.0,\n",
       " 32.0,\n",
       " 2.0,\n",
       " 22.0,\n",
       " 11.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 587.0,\n",
       " 33.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 37.0,\n",
       " 7.0,\n",
       " 63.0,\n",
       " 298.0,\n",
       " 11.0,\n",
       " 69.0,\n",
       " 54.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 12.0,\n",
       " 420.0,\n",
       " 600.0,\n",
       " 13.0,\n",
       " 5.0,\n",
       " 520.0,\n",
       " 13.0,\n",
       " 11.0,\n",
       " 33.0,\n",
       " 20.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 16.0,\n",
       " 14.0,\n",
       " 128.0,\n",
       " 3.0,\n",
       " 807.0,\n",
       " 22.0,\n",
       " 6.0,\n",
       " 25.0,\n",
       " 28.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 12.0,\n",
       " 6.0,\n",
       " 156.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 11.0,\n",
       " 24.0,\n",
       " 72.0,\n",
       " 2673.0,\n",
       " 19.0,\n",
       " 54.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 12.0,\n",
       " 33.0,\n",
       " 17.0,\n",
       " 13.0,\n",
       " 8.0,\n",
       " 11.0,\n",
       " 1.0,\n",
       " 10.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 13.0,\n",
       " 19.0,\n",
       " 15.0,\n",
       " 27.0,\n",
       " 268627.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 11.0,\n",
       " 24.0,\n",
       " 125.0,\n",
       " 1145.0,\n",
       " 126.0,\n",
       " 20.0,\n",
       " 574.0,\n",
       " 22.0,\n",
       " 75.0,\n",
       " 112.0,\n",
       " 255.0,\n",
       " 156.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 24.0,\n",
       " 2.0,\n",
       " 229.0,\n",
       " 2184.0,\n",
       " 45.0,\n",
       " 13.0,\n",
       " 16.0,\n",
       " 21.0,\n",
       " 96.0,\n",
       " 53.0,\n",
       " 0.84,\n",
       " 120178.0,\n",
       " 22.0,\n",
       " 34.0,\n",
       " 2.0,\n",
       " 42.0,\n",
       " 91.0,\n",
       " 20.0,\n",
       " 10.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 7.0,\n",
       " 4.0,\n",
       " 1.44,\n",
       " 17.0,\n",
       " 101.0,\n",
       " 17.0,\n",
       " 59.0,\n",
       " 22.0,\n",
       " 3168.0,\n",
       " 30.0,\n",
       " 229.0,\n",
       " 14.0,\n",
       " 2.0,\n",
       " 83.0,\n",
       " 31.0,\n",
       " 606.0,\n",
       " 574664.0,\n",
       " 6.0,\n",
       " 3834.0,\n",
       " 2436.0,\n",
       " 6.0,\n",
       " 174.0,\n",
       " 3.0,\n",
       " 60.0,\n",
       " 20.0,\n",
       " 14.0,\n",
       " 455.0,\n",
       " 106.0,\n",
       " 12.0,\n",
       " 70.0,\n",
       " 170.0,\n",
       " 35.0,\n",
       " 72.0,\n",
       " 15.0,\n",
       " 171.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 130.0,\n",
       " 592.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 17.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 43.0,\n",
       " 5852.0,\n",
       " 10.0,\n",
       " 45.0,\n",
       " 14.0,\n",
       " 9.0,\n",
       " 99.0,\n",
       " 27.0,\n",
       " 1.0,\n",
       " 11.0,\n",
       " 1.0,\n",
       " 2.0]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cffa91e4-a612-4c7a-bb35-7f3dcc136fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9862142099681867\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "corr = 0\n",
    "incorr = 0\n",
    "for i, j in zip(result, truth):\n",
    "    if i == j:\n",
    "        corr+=1\n",
    "    else:\n",
    "        incorr+=1\n",
    "      \n",
    "\n",
    "print('Accuracy:', corr/(corr+incorr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "426bd917-4cbc-4dd7-a5e4-1c80b92ed137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea9346-b94a-4640-9fee-154405f54430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
